{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import urllib\n",
    "from lxml import html\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import corpus\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import requests_cache\n",
    "requests_cache.install_cache('demo_cache')\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import statsmodels\n",
    "from scipy.interpolate import interp1d\n",
    "import warnings\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "import statsmodels.api\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>\n",
    " To analyze the possible factors affecting the house prices, we consider several factors to explain what the reasons cause this phenomenon. There are three parts we will cover: population density& house units, economics and social influence. \n",
    "</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>\n",
    "Letâ€™s start with the first part: the relationship between population density&house units and house prices. We find many articles consider the population as the basic factor. Therefore, we prefer to search for the population for each county and corresponding house units. In the plot, we can see that compared with other cities, there is really large population density in San Francisco. However, the large cluster of house units is mainly centered around Los Angles. Hence, we can infer that the large population density and low house units in San Francisco will lead the house prices to go up, which consists with the predict prices in last part. \n",
    "</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Country = [\"Los Angeles\",\"San Diego\",\"Orange\",\"Riverside\",\"Santa Clara\",\"Sacramento\",\"Fresno\",\"San Francisco\",\"Santa Barbara\",\"Santa Cruz\",\"Yolo\",\"San Mateo\",\"San Joaquin\",\"Kern\"]\n",
    "url_wi = \"https://en.wikipedia.org/wiki/List_of_California_locations_by_income\"\n",
    "page = requests.get(url_wi)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "dat = soup.find_all(\"table\",attrs={\"class\": \"wikitable sortable\"})\n",
    "dat_1 = dat[0].find_all(\"td\")\n",
    "re_county = []\n",
    "re_name = []\n",
    "for i in dat_1:\n",
    "    if i.a==None:\n",
    "        re_county.append(str(i.text))\n",
    "    else:\n",
    "        re_name.append(i.text)\n",
    "re_county = np.asarray(re_county)\n",
    "re_county = np.split(re_county, 58)\n",
    "data = pd.DataFrame(re_county)\n",
    "data[\"County\"] = re_name\n",
    "del data[2]\n",
    "del data[3]\n",
    "data.columns = ['population', 'population density','median family income','County']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "de = []\n",
    "for i in range(0,len(data[\"County\"])):\n",
    "    if data[\"County\"][i] not in Country:\n",
    "        de.append(i)\n",
    "data = data.drop(data.index[de])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import geocoder\n",
    "geolocator = Nominatim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat = []\n",
    "lon = []\n",
    "get_name = [str(i) for i in data['County']]\n",
    "for i in get_name:\n",
    "    location = geocoder.google(i)\n",
    "    lat.append(location.lat)\n",
    "    lon.append(location.lng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income = []\n",
    "for i in list(data['median family income']):\n",
    "    i = i.replace(\"$\",\"\")\n",
    "    i = i.replace(\",\",\"\")\n",
    "    i = int(i)\n",
    "    income.append(i)\n",
    "rate_in = [(float(i)/float(max(income)))*100 for i in income ]\n",
    "str_rate_in = [str(i) for i in rate_in]\n",
    "str_income = [str(i) for i in income ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd = []\n",
    "for i in list(data['population density']):\n",
    "    i = i.replace(\",\",\"\")\n",
    "    i = float(i)\n",
    "    pd.append(i)\n",
    "rate_pd = [(float(i)/float(max(pd)))*100 for i in pd ]\n",
    "str_rate_pd = [str(i) for i in rate_pd]\n",
    "str_pd = [str(i) for i in pd ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='gychenyolo', api_key='90gBEoe9LWXZO4iVgWj3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.sign_in('Timmy1123', 'ohjdklZmUwhrgU1CMYp3')\n",
    "trace1 = {\n",
    "  \"lat\": lat, \n",
    "  \"lon\": lon, \n",
    "  \"marker\": {\n",
    "    \"size\": str_rate_pd, \n",
    "    \"sizeref\": 2\n",
    "  }, \n",
    "  \"mode\": \"markers\", \n",
    "  \"name\": \"B\", \n",
    "  \"text\": str_pd, \n",
    "  \"type\": \"scattermapbox\", \n",
    "  \"uid\": \"469a5a\"\n",
    "}\n",
    "data1 = Data([trace1])\n",
    "layout = {\n",
    "  \"autosize\": True, \n",
    "  \"height\": 511, \n",
    "  \"hovermode\": \"closest\", \n",
    "  \"mapbox\": {\n",
    "    \"bearing\": 0, \n",
    "    \"center\": {\n",
    "      \"lat\": 35.3116418698, \n",
    "      \"lon\": -118.441428557\n",
    "    }, \n",
    "    \"pitch\": 0, \n",
    "    \"zoom\": 5.10790759747\n",
    "  }, \n",
    "  \"title\": \"Population density in  California\", \n",
    "  \"width\": 910\n",
    "}\n",
    "fig = Figure(data=data1, layout=layout)\n",
    "plot_url = py.plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "py.sign_in('Timmy1123', 'ohjdklZmUwhrgU1CMYp3')\n",
    "trace1 = {\n",
    "  \"lat\": lat, \n",
    "  \"lon\": lon, \n",
    "  \"marker\": {\n",
    "    \"size\": str_rate_in, \n",
    "    \"sizeref\": 4\n",
    "  }, \n",
    "  \"mode\": \"markers\", \n",
    "  \"name\": \"B\", \n",
    "  \"text\": str_income, \n",
    "  \"type\": \"scattermapbox\", \n",
    "  \"uid\": \"469a5a\"\n",
    "}\n",
    "data1 = Data([trace1])\n",
    "layout = {\n",
    "  \"autosize\": True, \n",
    "  \"height\": 511, \n",
    "  \"hovermode\": \"closest\", \n",
    "  \"mapbox\": {\n",
    "    \"bearing\": 0, \n",
    "    \"center\": {\n",
    "      \"lat\": 35.3116418698, \n",
    "      \"lon\": -118.441428557\n",
    "    }, \n",
    "    \"pitch\": 0, \n",
    "    \"zoom\": 5.10790759747\n",
    "  }, \n",
    "  \"title\": \"Income in  California\", \n",
    "  \"width\": 910\n",
    "}\n",
    "fig = Figure(data=data1, layout=layout)\n",
    "plot_url = py.plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9855897e0743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmall_name_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmall_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmall_locationt_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmall_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmall_inf_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmall_locationt_pd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmall_name_pd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'DataFrame'"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://en.wikipedia.org/wiki/List_of_shopping_malls_in_California')\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "dat = soup.find_all('div', attrs = {'id':\"mw-content-text\", 'class':\"mw-content-ltr\"})\n",
    "result = dat[0].find_all('li')\n",
    "mall_name = []\n",
    "mall_location = []\n",
    "for i in result:\n",
    "    try:\n",
    "        name  = i.find_all('a')[0].text\n",
    "        location = i.find_all('a')[1].text\n",
    "        mall_name.append(name)\n",
    "        mall_location.append(location)\n",
    "    except:\n",
    "        continue\n",
    "mall_name_pd = pd.DataFrame(mall_name)\n",
    "mall_locationt_pd = pd.DataFrame(mall_location)\n",
    "mall_inf_pd = pd.concat([mall_locationt_pd,mall_name_pd], axis = 1)\n",
    "mall_inf_pd.columns = ['Location', 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def art_search(url, numpages):\n",
    "    '''\n",
    "    Augument: \n",
    "        Given the base URl and the page number to get all the url of pages.\n",
    "        \n",
    "    Input:\n",
    "        URL and number of pages\n",
    "        \n",
    "    Output:\n",
    "        URL\n",
    "    \n",
    "    '''\n",
    "    urllist_1 = []\n",
    "    for i in range(numpages):\n",
    "        urllist = url + '&page='+ str(i+1) \n",
    "        urllist_1.append(urllist)\n",
    "    return urllist_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_list = art_search('https://www.viamichelin.com/web/Restaurants?geoboundaries=23.32208,-132.4511719:43.1330612,-108.28125', 22)\n",
    "zipcode = []\n",
    "resaurant = []\n",
    "county = []\n",
    "for link in search_list:\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    result = soup.find_all('div', attrs = {'class':'pois_index_list', 'data-view':'restaurants/index/list'})\n",
    "    dat = result[0].find_all('li')\n",
    "    for i in dat:\n",
    "        try:\n",
    "            inf = i.contents[2].a['href'].split('-')\n",
    "            county_1 = inf[0].split('/')\n",
    "            zipcode.append(inf[1])\n",
    "            resaurant.append(inf[2])\n",
    "            county.append(county_1[3])   \n",
    "        except:\n",
    "            continue\n",
    "zipcode_pd = pd.DataFrame(zipcode)\n",
    "resaurant_pd = pd.DataFrame(resaurant)\n",
    "county_pd = pd.DataFrame(county)\n",
    "resaurant_inf_pd = pd.concat([zipcode_pd, resaurant_pd, county_pd], axis = 1)\n",
    "resaurant_inf_pd.columns = ['Zipcode', 'Name', 'Location']\n",
    "xiao = []\n",
    "for i in list(resaurant_inf_pd[\"Location\"]):\n",
    "    i = i.replace(\"_\",\" \")\n",
    "    xiao.append(i)\n",
    "resaurant_inf_pd[\"Location\"] = xiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hotel_search(url, numpages):\n",
    "    '''\n",
    "    Augument: \n",
    "        Given the base URl and the page number to get all the url of article.\n",
    "        \n",
    "    Input:\n",
    "        URL and number of pages\n",
    "        \n",
    "    Output:\n",
    "        URL\n",
    "    \n",
    "    '''\n",
    "    urllist_1 = []\n",
    "    for i in range(numpages):\n",
    "        urllist = url + 'pg='+ str(i+1) \n",
    "        urllist_1.append(urllist)\n",
    "    return urllist_1\n",
    "search_list = hotel_search('http://www.luxurylink.com/inventory/main.php?kw=california&dtin=2017-04-05&dtout=2017-04-06&guests=2&nights=1&prc=&pmn=&pmx=&es=0&ot=&sort=r&pp=25&np=1&ev=0&&', 9)\n",
    "hotel_name = []\n",
    "hotel_loc = []\n",
    "for link in search_list:\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    dat = soup.find_all('div', attrs = {\"class\":\"large-8 columns\"})\n",
    "    res = dat[0].find_all('li')\n",
    "    for i in res:\n",
    "        try:\n",
    "            location  = i.h4.small.text\n",
    "            name = i.h4.contents[0]\n",
    "            hotel_name.append(name)\n",
    "            hotel_loc.append(location)\n",
    "        except:\n",
    "            continue\n",
    "hotel_name_pd = pd.DataFrame(hotel_name)\n",
    "hotel_loc_pd = pd.DataFrame(hotel_loc)\n",
    "hotel = pd.concat([hotel_loc_pd,hotel_name_pd], axis = 1)\n",
    "hotel.columns = ['Location', 'Hotel Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_rank = []\n",
    "school_location = []\n",
    "school_name = []\n",
    "school_name_1 = []\n",
    "response = requests.get('http://www.4icu.org/us/california/universities-california.htm')\n",
    "school_doc = response.text\n",
    "soup = BeautifulSoup(school_doc, 'lxml')\n",
    "result = soup.find_all('div', class_ = \"container\")\n",
    "result = result[0].find_all('table',class_= \"table table-hover\")\n",
    "result = result[0].find_all('tr')\n",
    "result = result[1:]\n",
    "for i in result:\n",
    "    rank = i.find_all('kbd')[0].contents[0]\n",
    "    school_rank.append(rank)\n",
    "    name = i.find_all('td')[1].contents[0]\n",
    "    school_name_1.append(name)\n",
    "    loc = i.find_all('td')[2].contents[0]\n",
    "    school_location.append(loc)\n",
    "school_name_1 = school_name_1[0:-1]\n",
    "for j in school_name_1:\n",
    "    school_name.append(j.contents[0])\n",
    "Name = pd.DataFrame(school_name)\n",
    "Rank = pd.DataFrame(school_rank)\n",
    "Location = pd.DataFrame(school_location)\n",
    "school = pd.concat([Rank, Name, Location], axis = 1)\n",
    "school.columns = ['Rank', 'School', 'Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school = school.drop(school.index[116])\n",
    "school = school.drop(school.index[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sch_loc = list(school[\"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_loc = list(resaurant_inf_pd[\"Location\"])\n",
    "mall_loc = list(mall_inf_pd[\"Location\"])\n",
    "hotel_loc = list(hotel[\"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Find_loc(list_names):\n",
    "    lng = []\n",
    "    lat = []\n",
    "    for i in list_names:\n",
    "        g = geocoder.google(str(i)+\",CA\")\n",
    "        print i\n",
    "        lat.append(g.lat)\n",
    "        lng.append(g.lng)\n",
    "    return lat,lng\n",
    "school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import geocoder\n",
    "loc1 = Find_loc(sch_loc)\n",
    "lonlat1 = pd.DataFrame(loc1[0],loc1[1])\n",
    "lonlat1[1] = lonlat1.index\n",
    "lonlat2[1] = lonlat2.index\n",
    "loc3 = Find_loc(mall_loc)\n",
    "lonlat3 = pd.DataFrame(loc3[0],loc3[1])\n",
    "lonlat3[1] = lonlat3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lonlat1 = lonlat1.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc4 = Find_loc(hotel_loc)\n",
    "lonlat4 = pd.DataFrame(loc4[0],loc4[1])\n",
    "lonlat4[1] = lonlat4.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lonlat_total = pd.concat([lonlat3,lonlat4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "CA = (36.7783, -119.4179)\n",
    "map_1 = folium.Map(CA, zoom_start=5)\n",
    "map_2 = folium.Map(CA, zoom_start=5)\n",
    "map_3 = folium.Map(CA, zoom_start=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "marker_cluster = folium.MarkerCluster(\"School cluster\").add_to(map_1)\n",
    "for each in lonlat1.iterrows():\n",
    "    folium.Marker(list((each[1][0],each[1][1]))).add_to(marker_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>\n",
    "We can easily find out that there are two school clusters on the map. The one is around Bay area, the other is near LA area. Simutaneously, these two areas have relatively high house price. So we guess that schools may attract many students of outstate and of other counties in California settling down after they graduate from universities. With more and more people settle around school, house price that nearby universities will be high, and the school cluster will push the entire county house price. Hence, we conclude that school clusters would be an important factor for house price.\n",
    "We notice that there are almost twice universities in LA area than in Bay area. However, the house price of Bay area is relatively higher than LA area. So there may be some factors that counteract the influence of universities. \n",
    "</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## \n",
    "marker_cluster1 = folium.MarkerCluster(\"Mall and hotel cluster\").add_to(map_2)\n",
    "for each in lonlat_total.iterrows():\n",
    "    folium.Marker(list((each[1][0],each[1][1]))).add_to(marker_cluster1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4>\n",
    "We use people income and the sum of the number of five star hotels and super shopping-mall to illustrate the purchasing power of residuals. With higher purchasing power, people can afford high house price. The county that have relative high purchasing power will keep a high house price. </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>\n",
    "We find that many luxury hotels and super shopping-malls locate in Bay area, LA and San Diego. Simutaneously, these three areas have relatively high house price. We may guess the high purchasing power enable residuals in these areas to afford the high house price. Hence, house price in these area would keep high.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
